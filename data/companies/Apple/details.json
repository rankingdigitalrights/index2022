{"id":"Apple","printName":"Apple, Inc.","basicInformation":"<p>Headquartered in the United States, Apple manufactures computers, smartphones, and other devices, and produces the iOS operating system and application software. As of late 2019, the company had a base of <a href=\"https://www.apple.com/newsroom/2020/01/apple-reports-record-first-quarter-results/\">1.5 billion active devices</a>.</p>","keyTakeawaysTitle":"Key takeaways","keyTakeaways":"<ul><li>Apple earned the highest privacy score of any digital platform we evaluated, and stood out for strong disclosure of its security policies. </li></ul><ul><li>Apple lacked transparency about its process for removing apps from the App Store for violations to iOS rules.</li></ul><ul><li>Apple lagged behind its peers on human rights due diligence, but strengthened its human rights commitments.</li></ul>","keyFindingsTitle":"Key findings","keyFindings":"<p><span className=\"font-bold\">Apple ranked sixth among digital platforms. </span>In 2020, the company published a human rights policy that made an <a href=\"https://s2.q4cdn.com/470004039/files/doc_downloads/gov_docs/2020/Apple-Human-Rights-Policy.pdf\">explicit public commitment</a> to protect freedom of expression and information. This came after shareholders <a href=\"https://www.sumofus.org/media/to-mark-new-iphone-release-sumofus-files-shareholder-proposal-demanding-apple-promotes-freedom-of-expression/\">proposed a resolution</a> pushing the company to assert a commitment to freedom of expression and information. The proposed resolution cited <a href=\"https://www.businessinsider.nl/apple-ignore-hong-kong-pro-democracy-app-hints-china-censorship-2020-7?international%3Dtrue%26r%3DUS\">Apple&rsquo;s 2019 removal</a> of news and information apps in Hong Kong, along with other App Store censorship incidents. In June 2020, the company <a href=\"https://www.nytimes.com/2020/06/23/technology/apple-announces-new-privacy-features.html\">announced new privacy-protective features</a> for iOS 14 that require third-party apps to ask for users&rsquo; permission before tracking them, a move that shocked app developers, including Facebook. Apple subsequently <a href=\"https://www.theverge.com/2020/9/3/21420176/apple-ios-14-tracking-permission-rule-developers-delay\">delayed the rollout</a> to 2021, eliciting public pressure from advocates <a href=\"https://rankingdigitalrights.org/wp-content/uploads/2020/10/Ranking-Digital-Rights-Joint-Letter-to-Apple-iOS14-delay.pdf\">including RDR</a>. Apple outscored all other digital platforms in the RDR Index on privacy, even though we could not account for the new privacy features in our scoring, due to the delayed rollout.</p>","changesTitle":"Changes since 2019","changes":"<ul><li>Apple published a commitment recognizing freedom of expression and information as a human right (G1).</li></ul><ul><li>Apple began reporting the number of app removal demands it receives from governments (F6) and publishing some information about its process for responding to private requests for user information (P10b).</li></ul>","keyRecommendationTitle":"Key recommendations","keyRecommendation":"<ul><li>Be transparent about rules enforcement. Apple should publish data about actions it takes to enforce its own rules, including about apps removed from its App Store, and strengthen mechanisms to appeal such enforcement decisions. </li></ul><ul><li>Strengthen human rights due diligence. Apple should commit to conducting robust, systematic human rights impact assessments on all aspects of its operations and business practices. The scope of these assessments should include evaluting risks to freedom of expression and information and the right to non-discrimination associated with the development and use of algorithmic systems and its targeted advertising policies and practices. </li></ul><ul><li>Increase user control. Apple should give users more options to control their own information. Targeted advertising should be <span className=\"italic\">off </span>by default. </li></ul>","governance":"<p>Apple ranked fifth among digital platform companies we evaluated, falling short on human rights due diligence in comparison to its U.S. peers. </p><ul><li><span className=\"font-bold\">Commitment to human rights: </span>Apple disclosed a clear and explicit commitment to protect and respect privacy and freedom of expression and information but failed to disclose a similar human rights commitment in its use and development of algorithmic systems (G1).</li></ul><ul><li><span className=\"font-bold\">Human rights due diligence: </span>Apple disclosed it conducts limited assessments of privacy risks associated with government regulations in the markets in which it operates (G4a), but did not provide evidence of conducting due diligence in other areas, including of its own policy enforcement, on its development and use of algorithmic systems, or on targeted advertising.</li></ul><ul><li><span className=\"font-bold\">Stakeholder engagement: </span>Apple failed to provide evidence of systematic engagement with stakeholders whose privacy and freedom of expression and information are directly impacted by the company (G5).</li></ul><ul><li><span className=\"font-bold\">Remedy: </span>Apple disclosed little about its remedy mechanisms to address users&rsquo; freedom of expression and information as well as privacy grievances (G6a) and even less about its processes for users and developers to appeal app removals from the App Store (G6b).</li></ul>","freedom":"<p>Apple lagged behind South Korea-based Kakao and most of its U.S. peers in this category. </p><ul><li><span className=\"font-bold\">Content moderation: </span>Apple did not clearly disclose platform rules and its process for enforcing them (F3a), including rules on bots (F13). Nor did it report any data about content removals and account suspensions for violations to these policies (F4a, F4b). It offered almost no information on whether or how it notifies users when content is removed (F8).</li></ul><ul><li><span className=\"font-bold\">Algorithmic use and content curation: </span>Apple revealed nothing about how it uses algorithms to curate, rank, or recommend content in its App Store (F12).</li></ul><ul><li><span className=\"font-bold\">Advertising content and targeting: </span>The company lacked transparency about its ad content and ad targeting rules and enforcement process (F3b, F3c), and it did not publish data on content removed for violating these rules (F4c).</li></ul><ul><li><span className=\"font-bold\">Censorship demands:</span> Apple was transparent about its process for responding to government censorship demands (F5a) but disclosed very little about censorship requests submitted through private processes (F5b). For the first time, it reported the number of government takedown requests for apps in its App Store, and it listed the types of subject matter associated with them, following through on a prior commitment to do so. It also began disclosing the number of App Store takedown requests from governments for alleged violations of Apple&#39;s own Terms of Service (F6), but none about private requests (F7).</li></ul>","privacy":"<p>Apple earned the highest privacy score, but fell short in key areas.</p><ul><li><span className=\"font-bold\">Handling of user data: </span>While Apple did disclose some information about what user data it collects and shares, and why, it did not disclose anything about its data inference policies (P3b). Apple remained the only platform in the RDR Index to disclose it does not track users around the web, but the company disclosed nothing about whether it collects information about users through third-party data brokers (P9). </li></ul><ul><li><span className=\"font-bold\">Government and private demands for user data: </span>Apple was transparent about its process for responding to government demands for user information (P10a), but disclosed less information about user information requests submitted through private processes (P10b). It provided data about government demands (P11a), but like its U.S. peers, Apple did not divulge the exact number of requests received for user data under the Foreign Intelligence Surveillance Act or National Security Letters, or the actions it took in response to these requests, since it is prohibited by <a href=\"https://www.law.cornell.edu/uscode/text/50/1874\">law</a> from doing so. It also committed to notify users when government entities demand access to their information (P12). It did not publish any data about private requests (P11b), nor did it commit to notify users when their information is requested through private processes (P12).</li></ul><ul><li><span className=\"font-bold\">Security:</span> Apple disclosed more about its security policies than any other digital platform we evaluated. It was fully transparent about its internal processes for keeping user information secure (P13) and offered resources and tools to help users protect their security (P17, P18). It was less clear about its policies on data breaches (P15), and it disclosed limited information about how it addresses security vulnerabilities (P14).</li></ul>"}