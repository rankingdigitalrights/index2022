{"id":"Facebook","printName":"Facebook, Inc.","basicInformation":"<p>Headquartered in the United States, Meta offers some of the world&rsquo;s most popular social networking and messaging services, including Facebook, Instagram, Messenger, and WhatsApp, which collectively had an estimated <a href=\"https://earthweb.com/meta-statistics/\">3.6 billion</a> monthly active users worldwide in 2021. The vast majority of Meta&rsquo;s revenue is derived from advertising.</p>","keyTakeawaysTitle":"Key takeaways","keyTakeaways":"<ul><li>Meta failed to show evidence that it conducts systematic human rights impact assessments in a variety of areas, including terms of service enforcement, targeted advertising policies and practices, development and deployment of algorithmic systems, and its zero-rating programs.</li></ul><ul><li>Meta&rsquo;s <a href=\"https://web.archive.org/web/20211122014901/https://transparency.fb.com/data/community-standards-enforcement/?from%3Dhttps%3A%2F%2Ftransparency.facebook.com%2Fcommunity-standards-enforcement\">transparency reports</a>, which still cover only Facebook and Instagram, had a critical gap: advertising. The company offered only fragmented data on content and account restrictions and no data on the number of ads the company restricts.</li></ul><ul><li>Meta was not transparent about how it handles user data. It provided incomplete information about its data-inference practices and limited options for users to control their data. It also failed to describe whether or how it acquires and processes user data through purchases, data-sharing agreements, and other contractual relationships with third parties.</li></ul>","keyFindingsTitle":"Key findings","keyFindings":"<p>Meta had another year of tumult in the public eye and lackluster performance in our evaluation. Documents released by former-employee-turned-whistleblower Frances Haugen corroborated years of<a href=\"https://globalvoices.org/specialcoverage/2018-special-coverage/from-the-gv-archives-human-rights-in-the-facebook-era/\">accusations and grievances</a> from global civil society concerning human rights harms stemming from the company&rsquo;s services. They also brought irrefutable proof that Meta routinely breaks or ignores its own rules, especially outside the U.S.</p><p>In 2021, we saw plenty of new evidence of such problems. Meta neglected a scourge of harmful content in non-Western countries, including state-backed manipulation campaigns in <a href=\"https://www.theguardian.com/technology/2021/apr/13/facebook-azerbaijan-ilham-aliyev\">Azerbaijan</a> and <a href=\"https://www.theguardian.com/technology/2021/apr/13/facebook-honduras-juan-orlando-hernandez-fake-engagement\">Honduras</a>. It was slow to address <a href=\"https://time.com/6072272/facebook-sanatan-sanstha-india/\">hate speech</a> in India, and <a href=\"https://www.nytimes.com/2021/05/19/technology/israeli-clashes-pro-violence-groups-whatsapp.html?referringSource%3DarticleShare\">incitement</a> to mob violence by Israeli extremists against Palestinians on WhatsApp. Meta <a href=\"https://www.middleeasteye.net/news/israel-palestine-facebook-investigation-social-media-posts-suppression\">did hire</a> the independent firm <a href=\"https://www.bsr.org/\">BSR</a> to conduct a human rights-based assessment of its impacts in Palestine during the period of escalated violence that took place in May and June of 2021, but BSR&rsquo;s findings had not been released at the time of publication. In contrast to these crises, Meta <a href=\"https://about.fb.com/news/2022/02/metas-ongoing-efforts-regarding-russias-invasion-of-ukraine/\">responded</a> immediately to Russia&rsquo;s invasion of Ukraine in February 2022, devoting extra staffing to content review and publishing regular updates on how it handles war-related disinformation and hate speech.</p><p>It was no surprise to find that Meta&rsquo;s content moderation policies lacked clarity and consistency, and that the company failed to show clear evidence that it conducts human rights impact assessments of its terms of service enforcement. It also provided incomplete data about actions it takes to restrict content and accounts violating its rules. This is especially important in light of the company&rsquo;s decision to temporarily suspend the account of former U.S. President Donald Trump following the January 6 attack on the U.S. Capitol, and the subsequent release of evidence (also by whistleblower Haugen) that Meta had been giving special treatment to the accounts of high-profile politicians and celebrities through its &ldquo;XCheck&rdquo; program.</p><p>Meta&#39;s dual-class share structure continued to be a key factor undercutting efforts to hold the company to account for these harms. Under this structure, CEO Mark Zuckerberg retains 57% of voting power. Shareholders have <a href=\"https://www.morningstar.com/articles/1061237/how-facebook-silences-its-investors\">proposed resolutions to scrap</a> this structure every year since 2014. In 2021, without Zuckerberg&rsquo;s votes, this resolution would have netted 90% support.</p><p>The company&rsquo;s name change (from Facebook to Meta) and its stated intention to focus on developing a future virtual reality-driven &ldquo;metaverse&rdquo; signal a strong inclination to look ahead and build new technologies. This begs the question: How can the company uphold its human rights obligations if it does not first reflect on the harms it has caused and address its many existing policies and practices that so urgently need repair?</p>","changesTitle":"Changes since 2020","changes":"<ul><li>In a new <a href=\"https://web.archive.org/web/20211102162552/https://about.fb.com/wp-content/uploads/2021/04/Facebooks-Corporate-Human-Rights-Policy.pdf\">human rights policy</a> released in 2021, Meta disclosed that human rights guide its use and development of artificial intelligence, although it did not ground this commitment in international human rights standards. </li></ul><ul><li>Instagram lost points on remedy. The company published a <a href=\"https://about.fb.com/news/2018/04/comprehensive-community-standards/\">blog post</a> in 2018 that offered a time frame for reviewing appeals of content removals on Instagram, but this information was never incorporated into formal company policy. The blog post is now out of date by our standards, so we are not giving Meta credit on this element.</li></ul><ul><li>WhatsApp users lost important mechanisms for controlling their data. In our 2020 evaluation, WhatsApp&#39;s <a href=\"https://web.archive.org/web/20211104143549/https://www.whatsapp.com/legal/privacy-policy\">privacy policy</a> indicated that users could choose not to have their account information shared with Facebook. In our 2022 evaluations, we found this statement had been removed from the privacy policy. Meta also added new details indicating that users&#39; data is being used for advertising without any opt-out or control options.</li></ul>","keyRecommendationTitle":"Key recommendations","keyRecommendation":"<ul><li>Improve human rights due diligence. Meta should carry out comprehensive human rights impact assessments on its own policy enforcement, targeted-advertising practices, algorithmic use and development policies, and zero-rating partnerships.</li></ul><ul><li>Be more transparent about government censorship demands. Meta should clarify its process for responding to government censorship demands targeting content and accounts of WhatsApp and Facebook Messenger users. It should expand the data it publishes about these types of demands by including a breakdown of the total quantity of demands per country, listing the number of accounts affected, and identifying the subject matter associated with those demands.</li></ul><ul><li>Clarify handling of user information. Meta should be more transparent about its data-inference practices and provide its users with better options and tools to control their information. It should also clarify whether (and how) it acquires user information from third parties through non-technical means.</li></ul><ul><li>Include data in the transparency report about advertising rules enforcement. Meta should share the volume and nature of actions it takes to restrict advertising content that violates its advertising content policies and advertising targeting policies.</li></ul>","governance":"<p>Meta tied with Microsoft for first place in governance among digital platforms. The company published a clear commitment to protect and respect privacy and freedom of expression and information, and also published a new <a href=\"https://web.archive.org/web/20211102162552/https://about.fb.com/wp-content/uploads/2021/04/Facebooks-Corporate-Human-Rights-Policy.pdf\">human rights policy</a> in which it pledged to let human rights guide its development and use of AI. This policy did not say whether Meta would fully adhere to international human rights standards in these activities (G1). Despite the presence of Meta&rsquo;s Free Basics program in numerous countries, the company published no evidence to suggest that it conducts human rights due diligence on its deployment of zero-rating schemes (G4e).</p>","freedom":"<p>Meta ranked fifth in this category, lacking transparency about its policies affecting users&rsquo; freedom of expression and information, including ad-content and ad-targeting rules. The company disclosed some information on how it uses algorithms to curate, rank, and recommend content on Facebook, but this information was incomplete. Disclosures related to algorithms were weaker for Instagram than for Facebook. The company failed to explain how users can control the variables that Instagram&rsquo;s algorithmic systems take into account, and whether or not these systems are on by default (F12). Meta provided no proof of whether or how it enforces its advertising content and targeting rules (F4c).</p>","privacy":"<p>Lagging behind all but one of its U.S. peers (Amazon), Meta was clear about how it responds to government demands for user information (P10a) but failed to explain how it handles that information internally. Although Meta&rsquo;s <a href=\"https://web.archive.org/web/20211104140047/https://www.facebook.com/policy.php\">data policy</a> provided a clear overview of what data Facebook collects (P3a), the company only described isolated examples of the data it infers (P3b). Meta had the lowest score of any digital platform we evaluated on its transparency regarding options for users to control how their data is collected, inferred, retained, and processed (P7). </p>"}