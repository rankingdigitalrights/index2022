{"id":"G06b","name":"G6b","category":"governance","label":"Process for content moderation appeals","description":"The company should offer users clear and predictable <a href='#glossary-appeal'>appeals</a> mechanisms and processes for appealing <a href='#glossary-contentmoderation'>content-moderation actions</a>.","guidance":"<p>No matter how carefully a platform crafts its terms of service, mistakes are inevitable in the demanding and subjective endeavor of content moderation. This is particularly true when content moderation is scaled rapidly through the use of automation. To respect users' freedom of expression and information rights, companies should provide a robust and transparent appeals system that enables users to appeal decisions made by the company that directly influence users' ability to exercise these rights. Companies should clearly disclose their process for appealing content moderation actions, including enabling affected users to immediately appeal that action.</p> <p>A robust appeals process should include oversight by a human reviewer and give affected users an opportunity to present additional information. Companies should also offer a clear timeframe for reviewing appeals and clearly disclose the circumstances in which appeals are not possible.</p> <p>To receive full credit on this indicator, companies should inform users how to submit an appeal and describe what happens once the appeal enters the pipeline. This includes notifying users of their options for appeal as soon as the company takes an initial action on their content, clarifying the role of both automation and independent human moderators in the appeals process, clearly disclosing the reason for an appeals decision and the timeframes involved, and specifying circumstances in which the appeals process is not available. Companies should also clearly demonstrate they respond to appeals by publishing data on the appeals received and the outcome of those decisions.</p>","isParent":false,"hasParent":true}