{"id":"F13","name":"F13","category":"freedom","label":"Automated software agents (“bots”)","description":"Companies should <a href='#glossary-clearlydisclose'>clearly disclose</a> policies governing the use of <a href='#glossary-bot'>automated software agents (“bots”)</a> on their platforms, products and services, and how they enforce such policies.","guidance":"<p>Social media platforms often allow users to create automated software agents, or “bots,” that automate various actions a user account can take, such as posting or boosting content (re-tweeting, for example). There are many innocuous or even positive uses of bots—for instance, artists use Twitter bots for the purpose of parody. There are also more problematic uses that many companies forbid or discourage, such as when political parties or their surrogates use botnets to promote certain messages or to artificially inflate a candidate's reach in order to manipulate public discourse and outcomes. On some social media platforms, bots or coordinated networks of bots (“botnets”) can be used to harass users (“brigading”), artificially amplify certain pieces of content (mass retweeting, etc), and otherwise distort public discourse on the platform. Some experts have called for companies to require users who use bots to explicitly label them as bots, in order to help detect such distortions.</p> <p>Companies that allow bots therefore should have clear policies governing the use of bots on their platforms.</p> <p>They should disclose whether they require content and accounts that are produced, disseminated or operated with the assistance of a bot to be labelled as such. They should also clarify their process for enforcing their bot policies, including by publishing data on the volume and nature of content and accounts that are restricted for violating these rules.</p>","isParent":false,"hasParent":false}