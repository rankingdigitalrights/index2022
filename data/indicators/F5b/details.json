{"id":"F05b","name":"F5b","category":"freedom","label":"Process for responding to private requests for content or account restriction","description":"The company should <a href='#glossary-clearlydisclose'>clearly disclose</a> its process for responding to <a href='#glossary-privateprocesses'>requests</a> to remove, filter, or restrict <a href='#glossary-contentrestriction'>content</a> or <a href='#glossary-accountrestriction'>accounts</a> that come through private processes.","guidance":"<p>In addition to demands from governments and other types of authorities, companies can receive requests to remove or restrict access to content and accounts through private processes. These types of requests can come through formal processes established by law, (e.g., requests made under the U.S. Digital Millennium Copyright Act, the European Right to be Forgotten ruling, etc.) or via self-regulatory arrangements (e.g., company agreements to block certain types of materials or images, such as via the EU's Code of Conduct on Disinformation).</p> <p>Note that this indicator does not regard private requests to be requests that come through any kind of court or judicial process, which are considered under “government” requests (Indicator F5a).</p> <p>This indicator evaluates whether the company clearly discloses how it responds to requests to remove, filter, or restrict content or accounts that come through these types of private processes (Element 1). The company should disclose the basis for complying with these types of requests (Element 2), and whether it conducts due diligence on these requests before deciding how to respond (Element 3). We also expect companies to commit to push back on overly broad requests to remove content or accounts that come through private processes (Element 4), and to publish clear examples that illustrate how a company handles these types of requests (Element 5).</p>","isParent":false,"hasParent":true}