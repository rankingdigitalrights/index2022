{"pageTitle":"Executive Summary","body":"<p>The <span className=\"italic font-bold\">2022 RRD Big Tech Scorecard</span> marks the sixth edition of our rankings, formerly known as the RDR Corporate Accountability Index, and the first time we have looked at digital platforms separately from telecommunications companies (our renamed Teleco Giants Scorecard will come out in Q4 2022). This research evaluates 14 digital platforms across more than 300 aspects of company and service policies and practices, generating hundreds of thousands of data points about these big tech firms&rsquo; disclosed commitments affecting corporate governance, freedom of expression, and privacy.     </p><p>In 2021, once again, none of the 14 digital platforms we evaluated earned a passing grade. Despite poor marks overall, many companies made incremental strides in areas such as corporate governance management and privacy. Whatever gains achieved, however, are challenged by the troubling conclusion that, amid Russia&rsquo;s war against Ukraine, democratic instability in the West, and conflict in the Global South, companies are content to conduct business as usual. The state of the world demands more. For the largest big tech firms, we expect a greater alignment of company policies and practices with human rights&ndash;based standards and their obligations under the UN Guiding Principles. This means making fundamental changes to rights-abusing business models&ndash;particularly those that rely upon online advertising systems&ndash;, dismantling barriers to shareholder activism, and bolstering due diligence and trust and safety initiatives in the Global South. </p><h2 id=\"the-2022-big-tech-scorecard\">The 2022 Big Tech Scorecard</h2><p>The 2020 Big Tech Scorecard features several additions. New this year, we call out scores on specific services, including e-commerce, virtual assistants, and Microsoft&rsquo;s LinkedIn, a newcomer to the ranking. This year also offers the first chance for us to look at whether companies have made any progress improving indicators related to the development and deployment of both algorithmic and targeted-advertising systems since they were first introduced in our last <a href=\"https://rankingdigitalrights.org/index2020/indicators/P1b\">scorecard</a>. </p><img alt=\"\" src=\"executive-summary/image2.jpg\" title=\"\"/><p>Twitter again took the top spot, for its detailed content policies and public data about moderation of user-generated content. </p><ul><li>Yandex had the highest score change (7.6 points), thanks to policy improvements in all three categories: governance, freedom of expression, and privacy</li><li>Amazon, despite a notable score increase, remained dead last, alongside Chinese behemoth Tencent. It also earned the lowest score (20%) among all social media platforms we rank on our standard asking companies to explain their processes of enforcing their own content rules. </li><li>Google had the fewest improvements, and for the second year in a row, it was the only company that saw its overall score decline, due to outdated policies on notifying search service users of content restrictions and encryption for Gmail and Google Drive. </li></ul><h3 id=\"h.cfvzcizcz7b4\">Surprising finding? Chinese platforms </h3><p>The Chinese companies were among the least transparent platforms, but still showed improvement, in part as a result of Beijing&rsquo;s <a href=\"https://rankingdigitalrights.org/2021/12/08/who-has-the-power-the-party-the-public-and-big-tech-in-china/\">sweeping crackdown</a> on the once freewheeling sector. To respond to the rapidly changing regulatory environment, both Baidu and Tencent provided more information about their governance processes, which led to notable score improvements in the governance category. In complying with China&rsquo;s new <a href=\"https://digichina.stanford.edu/work/translation-personal-information-protection-law-of-the-peoples-republic-of-china-effective-nov-1-2021/\">Personal Information Protection Law</a> (PIPL), Tencent, Baidu, and Alibaba provided users with the ability to opt out of the algorithmic recommendation systems of their major services. </p><p>As in previous years, the Chinese companies kept silent about how they handle government requests and published only superficial data about content removed and accounts restricted. <span className=\"font-bold\">Plug Jie&rsquo;s essay on Chinese company engagement</span></p><h2 id=\"the-good\">The Good</h2><p>Since the inaugural RDR Index, the number of digital platforms that publicly commit to protecting users&rsquo; freedom of expression and privacy continues to grow. The number of companies that undertake any type of human rights due diligence has also increased annually. </p><p>In 2021, the order of the top seven companies in our ranking did not change since last year. All companies except Google, which declined slightly, made at least small net improvements to their policies affecting privacy and freedom of expression. </p><p>For the third year running, digital platforms headquartered outside the U.S. led year-over-year changes. Chinese companies Baidu and Tencent gained nearly 3 points and Yandex had the highest score change due, in part, to its publication of transparency reports that offered some insight into how it handles government demands to access user data, and for the first time since RDR started ranking the company in 2017, it disclosed a policy on handling data breaches. </p><p>Many companies also enhanced their corporate governance practices. Eight companies improved their scores on <a href=\"https://rankingdigitalrights.org/index2022-stg/indicators/G2\">governance and management oversight</a>, as a result of instituting committees or other upper-management mechanisms to oversee the effects of company practices on freedom of expression and privacy  More broadly, the highest score change on average came from improvements in disclosures on <a href=\"https://rankingdigitalrights.org/index2022-stg/indicators/P13\">security practices</a>, including limiting employee access to data and both internal and third-party security auditing. </p><ul><li>Yahoo&mdash;formerly Verizon Media, and now the only company we rank that is not publicly traded since its acquisition by private equity firm Apollo Global Management&mdash;gained almost three points, thanks to improved security and data breach policies</li><li>Microsoft disclosed more about content governance, releasing data for the first time on content it restricted based on its own rules. Its Bing search engine disclosed more data about how it moderates advertising content than any other service we ranked.</li><li>Kakao, the only non-U.S. company in the top half of the Big Tech Scorecard,  launched a board-level committee to oversee issues including privacy and freedom of expression.</li></ul><h2 id=\"the-bad\">The Bad</h2><h3 id=\"h.if5bzt14ugj2\"><span className=\"font-bold italic\">Still reckoning with the business model: to fix the internet, we must first fix online ads. </span></h3><p>For the second year in a row, none of the 14 companies we rank earned more than 50% of the possible points on our targeted advertising indicators. Companies typically have <a href=\"https://rankingdigitalrights.org/index2020/indicators/F1b\">rules for ad content</a> and for <a href=\"https://rankingdigitalrights.org/index2020/indicators/F1c\">ad targeting</a>, but independent research suggests that they sometimes do a bad job at enforcing these rules. Our own research shows that among the industry&rsquo;s leaders, there is virtually <a href=\"https://rankingdigitalrights.org/index2020/indicators/F4c\">no transparency reporting</a> about ad policy enforcement.  </p><p>Companies fared even worse on algorithmic transparency, where the highest score was Yahoo&rsquo;s 22.45%. Civil society, investors, policymakers, and the public all clamor for basic transparency about these systems that impact every facet of our lives, to no avail. </p><p><span className=\"font-bold\">Plug Nathalie&rsquo;s ad essay</span></p><h3 id=\"h.kv1y7cvdc4cq\"><img alt=\"\" src=\"executive-summary/image1.jpg\" title=\"\"/><span className=\"font-bold italic\">Companies are stonewalling their users when it comes to how they develop and deploy algorithmic systems and infer data.  </span></h3><p>In <a href=\"https://rankingdigitalrights.org/index2020/indicators/P1b\">our last scorecard</a>, we debuted standards for disclosures about the development and deployment of both algorithmic and targeted-advertising systems. No company scored well on these standards. Have the ranked companies made any progress on these indicators since then? The short answer is a resounding No. </p><p>Of all companies, only Microsoft earned any credit for providing <a href=\"https://rankingdigitalrights.org/index2022-stg/indicators/P1b\">access to algorithmic system development policies</a>, the result of LinkedIn (new to our Scorecard this year) providing vague explanations of how it uses user data to develop machine learning models and how the company addresses bias in large-scale artificial intelligence (AI) applications.  </p><p>Companies did somewhat better in disclosing information about how they use algorithms to curate, recommend, and rank content, but in most cases stop short of what kind of controls users have over them. No company discloses that it limits the data that can be inferred to what is necessary to provide the service offered.</p><h3 id=\"h.u9jlmxafyyb5\"><span className=\"font-bold italic\">Companies are engaging more with civil society and investors but ignoring the need for engagement on algorithms and ads, and they are neglecting users&rsquo; rights to remedy.</span></h3><p>As a part of our research methodology, we offer companies an opportunity to review our preliminary results and make arguments&mdash;supported by evidence that meets our criteria&mdash;that they should earn credit where we saw none. This year, every platform we rank except the Chinese ones and, perplexingly, Google offered such feedback. </p><p>While Alibaba, Baidu, and Tencent have fewer incentives to engage with the human rights community, Google&rsquo;s lack of input is an anomaly among U.S. platforms for which we have no explanation. It is also deeply concerning, given the power the company has to shape our information environment through its dominant search and advertising services. </p><p>Users also have a right to contest decisions made about their content and accounts. Every digital platform should maintain open channels through which users can voice their concerns and seek remedy when a platform causes harm. Yet our data shows that companies are still failing to prioritize remedy mechanisms.</p><p>Since our last round of evaluations, we have noted virtually no improvements in this area. This lack of attention to upgrading remedy policies is especially disappointing at a time when human rights actors are <a href=\"https://santaclaraprinciples.org/\">increasingly coalescing</a> around the importance of these disclosures. </p><h3 id=\"h.gwxp1saljzs1\"><span className=\"font-bold\">Policy Recommendations </span></h3><p><span className=\"font-bold\">Towards a responsible and accountable online ad ecosystem</span></p><p>Achieving the vision of a global internet that supports and sustains human rights will require a global online advertising ecosystem that does the same thing. But the companies that dominate the digital ad market have little incentive to change their ways. This means that it is high time for policymakers to constrain these corporate behaviors and abuses of power through law and regulation.</p><ul><li><span className=\"font-bold\">Policymakers should pursue a wholesale ban on surveillance advertising</span>. Above all else, we believe that surveillance advertising&mdash;built on a foundation of privacy violations and discrimination by algorithm&mdash;must be banned in order to engineer a shift to an approach that respects human rights, such as<a href=\"https://www.investopedia.com/terms/c/contextual-advertising.asp\">contextual advertising</a>. </li></ul><ul><li><span className=\"font-bold\">With or without a total ban on surveillance advertising, policymakers should pass legislation that requires:</span></li></ul><ul><li><span className=\"font-bold\">Corporate transparency:</span> Companies should have transparent and well-enforced policies about<a href=\"https://rankingdigitalrights.org/index2020/indicators/F1b\">ad content</a>,<a href=\"https://rankingdigitalrights.org/index2020/indicators/F1c\">ad targeting</a>, where ads will appear (&ldquo;brand safety&rdquo;),<a href=\"https://www.aljazeera.com/economy/2022/3/15/inside-facebook-and-bjps-world-of-ghost-advertisers\">who can purchase ads</a>, and<a href=\"https://www.aljazeera.com/economy/2022/3/16/facebook-charged-bjp-lower-rates-for-india-polls-ads-than-others\">how prices are set</a>. They should include data about<a href=\"https://rankingdigitalrights.org/index2020/indicators/F4c\">ad policy enforcement</a> in their transparency reporting. They should be compelled to disclose how they comply with various legal requirements related to advertising (including political advertising) in the countries where they show ads. They should also be required to report on their progress toward linguistic equity: companies that accept ads in a given language should be able to effectively moderate ads in that language.</li><li><span className=\"font-bold\">Human rights due diligence and independent auditing:</span> Companies should conduct<a href=\"https://rankingdigitalrights.org/index2020/indicators/G4c\">human rights impact assessments</a> on all of their ad policies and relevant enforcement processes. They should also enable independent researchers and regulatory bodies to access data about advertising, including data that can help them independently verify company claims about rule enforcement.</li><li><span className=\"font-bold\">Appeal and remedy:</span> All enforcement systems produce errors, which is why appeals and other remedy systems are essential. Advertisers should be able to appeal when their ads are incorrectly rejected, and public-interest regulators should create mechanisms to ensure that prohibited ads don&rsquo;t make it through, for example by requiring external third-party audits of ad moderation systems.</li></ul><p><span className=\"font-bold\">Removing barriers that block shareholders from addressing  human rights issues</span></p><p>The human rights impacts of technology have become glaring enough to shake up the financial markets that give Big Tech companies life. Shareholders have emerged as a powerful voice in the push for corporate accountability in the tech sector&mdash;and often as powerful allies of the human rights community. But the chips are often still stacked against them in their efforts to press for change. <span className=\"font-bold\">(Plug Jan&rsquo;s ESG/SEC essay)</span></p><p>In order to give people a true stake in the companies where they hold shares, we must abolish the systemic forces that have allowed companies to amass power at the top. U.S. Policymakers should</p><ul><li><span className=\"font-bold\">End multi-class share structures.</span> Congress must mandate that companies with existing unequal voting structures adopt sunset provisions, and that newly public companies be barred from offering non-voting share classes entirely. Until these structures are fully abolished, companies that maintain them should be required to publicly disclose the disparity between ownership and voting power.</li><li><span className=\"font-bold\">Repeal rules that hinder shareholder action on human rights. </span>The SEC must rescind rules passed in 2020 that restrict shareholder participation according to stock ownership (which marginalize small shareholders), raise the thresholds of support needed for shareholders to resubmit proposals, and limit shareholders&rsquo; ability to build coalitions. </li></ul>"}